{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTVCDd3ZwnzM"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "pip install -q langchain_community langchain_huggingface faiss-cpu gradio openai torch torchvision torchaudio youtokentome pypdf accelerate google-generativeai langchain-google-genai streamlit pillow genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%shell\n",
        "\n",
        "# Install the custom version of NeMo by AI4Bharat\n",
        "wget https://indic-asr-public.objectstore.e2enetworks.net/ai4b_nemo.zip\n",
        "\n",
        "unzip -q /content/ai4b_nemo.zip && cd NeMo\n",
        "bash reinstall.sh\n",
        "\n",
        "cd .."
      ],
      "metadata": {
        "id": "vkbpf_RuxpKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%shell\n",
        "\n",
        "git clone -q https://github.com/VarunGumma/IndicTransTokenizer\n",
        "cd IndicTransTokenizer\n",
        "pip install -q --editable ./\n",
        "cd ..\n"
      ],
      "metadata": {
        "id": "43F7JhKRx8kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%shell\n",
        "\n",
        "apt-get install libsndfile1-dev ffmpeg\n",
        "\n",
        "git clone https://github.com/gokulkarthik/TTS\n",
        "cd TTS\n",
        "\n",
        "pip3 install -e .[all]\n",
        "pip3 install -r requirements.txt\n",
        "\n",
        "cd ..\n"
      ],
      "metadata": {
        "id": "hl4cNTqeyqzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "# INFO: If you're unable to import these libraries, just rerun this cell again.\n",
        "\n",
        "import gradio as gr\n",
        "from torch import cuda, inference_mode\n",
        "import nemo.collections.asr as nemo_asr\n",
        "from IndicTransTokenizer import IndicProcessor\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n"
      ],
      "metadata": {
        "id": "fvGC3K2xzkcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\" if cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"Using device: {DEVICE}\")"
      ],
      "metadata": {
        "id": "s5BerWQZzuPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "cNLiGyDdzxwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download PM-KISAN offical PDF document\n",
        "# https://www.pmkisan.gov.in/Documents/RevisedPM-KISANOperationalGuidelines(English).pdf\n",
        "\n",
        "%%shell\n",
        "\n",
        "gdown 1qXyBzQ_1uNCocPMAl9Z58UlZGteKl5kg"
      ],
      "metadata": {
        "id": "GOJpQg-1z1pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pm_kisan_doc = \"/content/PM-KISANOperationalGuidelines(English).pdf\""
      ],
      "metadata": {
        "id": "YjF3Z2xYz5WY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=600,\n",
        "    chunk_overlap=100\n",
        ")\n",
        "\n",
        "loader = PyPDFLoader(pm_kisan_doc)\n",
        "pages = loader.load_and_split(text_splitter=text_splitter)\n",
        "\n",
        "pages_chunks = [page.page_content for page in pages]\n",
        "print(f\"Generated {len(pages_chunks)} chunks of {pm_kisan_doc}\")"
      ],
      "metadata": {
        "id": "Imdd8YuEz-NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages_chunks[8]"
      ],
      "metadata": {
        "id": "DFV9rQrw0C4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow -y\n",
        "!pip install tensorflow-gpu"
      ],
      "metadata": {
        "id": "AIYRFDpDwghG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "faiss = FAISS.from_texts(pages_chunks, embeddings)"
      ],
      "metadata": {
        "id": "QRjJ2Gc60JVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test query\n",
        "result = faiss.similarity_search(\"what are the benefits of PM kisan yojna\", k=3)"
      ],
      "metadata": {
        "id": "klgJleSF0NKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This returns the most relevant doc similar to the query\n",
        "\n",
        "print(result[0].page_content)"
      ],
      "metadata": {
        "id": "zL4yPubA0RMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install genai"
      ],
      "metadata": {
        "id": "ZAPz_auJIl55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import genai\n",
        "\n",
        "genai.configure(api_key=os.environ[\"OPENAI_API_KEY\"])"
      ],
      "metadata": {
        "id": "AN7uHZxT0VDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai langchain-google-genai streamlit pillow"
      ],
      "metadata": {
        "id": "rdzJU8-w6Gdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "def get_gemini_output(prompt, temperature=0.2):\n",
        "    \"\"\"\n",
        "    Returns the response from the Gemini AI API.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): The input prompt to the API.\n",
        "        temperature (float): The temperature of the Gemini AI API.\n",
        "\n",
        "    Returns:\n",
        "        str: The response content from the Gemini AI API.\n",
        "    \"\"\"\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    response = model.generate_content(\n",
        "        prompt,\n",
        "        generation_config=genai.types.GenerationConfig(\n",
        "            candidate_count=1,\n",
        "            stop_sequences=['.'],\n",
        "            max_output_tokens=200,\n",
        "            top_p=0.6,\n",
        "            top_k=5,\n",
        "            temperature=temperature\n",
        "        )\n",
        "    )\n",
        "    return response.text\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "FPOch51J28Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_gemini_output(\"who are you\")"
      ],
      "metadata": {
        "id": "F55V8yIs6yAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ip = IndicProcessor(inference=True)"
      ],
      "metadata": {
        "id": "MjG5a_fc_uut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "en2indic_tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indictrans2-en-indic-dist-200M\", trust_remote_code=True)\n",
        "en2indic_model = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/indictrans2-en-indic-dist-200M\", trust_remote_code=True)"
      ],
      "metadata": {
        "id": "1vjGK9Fk_zI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "indic2en_tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indictrans2-indic-en-dist-200M\", trust_remote_code=True)\n",
        "indic2en_model = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/indictrans2-indic-en-dist-200M\", trust_remote_code=True)"
      ],
      "metadata": {
        "id": "2o36sBwfyVQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_tokenizer_config = {\n",
        "    \"en2indic\": {\n",
        "        \"tokenizer\": en2indic_tokenizer,\n",
        "        \"model\": en2indic_model,\n",
        "    },\n",
        "    \"indic2en\": {\n",
        "        \"tokenizer\": indic2en_tokenizer,\n",
        "        \"model\": indic2en_model,\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "sxhqe4ZbAHh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indic_translate(src_lang: str, tgt_lang: str, sents_to_translate: list):\n",
        "\n",
        "  \"\"\"\n",
        "  Uses IndicTrans2-200M distilled model to translate a list of sentences from a src_lang to tgt_lang\n",
        "\n",
        "  Args:\n",
        "      src_lang (str): The input sentences language.\n",
        "      tgt_lang (str): The language in which we want the sentences to be translated to.\n",
        "      sents_to_translate (list): The list of input sentences.\n",
        "\n",
        "  Returns:\n",
        "      outputs: The list of translated sentencesin tgt_lang.\n",
        "  \"\"\"\n",
        "\n",
        "  lang_map = {\n",
        "    \"punjabi\": \"pan_Guru\",\n",
        "    \"bengali\": \"ben_Beng\",\n",
        "    \"malayalam\": \"mal_Mlym\",\n",
        "    \"marathi\": \"mar_Deva\",\n",
        "    \"tamil\": \"tam_Taml\",\n",
        "    \"gujarati\": \"guj_Gujr\",\n",
        "    \"telugu\": \"tel_Telu\",\n",
        "    \"hindi\": \"hin_Deva\",\n",
        "    \"kannada\": \"kan_Knda\",\n",
        "    \"odia\": \"ory_Orya\",\n",
        "    \"english\": \"eng_Latn\"\n",
        "    }\n",
        "\n",
        "  src_lang = lang_map[src_lang]\n",
        "  tgt_lang = lang_map[tgt_lang]\n",
        "\n",
        "  if src_lang == \"eng_Latn\":\n",
        "    tokenizer = model_tokenizer_config[\"en2indic\"][\"tokenizer\"]\n",
        "    model = model_tokenizer_config[\"en2indic\"][\"model\"]\n",
        "\n",
        "    print(f\"Using en2indic, src_lang: {src_lang}, tgt_lang: {tgt_lang}\")\n",
        "\n",
        "  else:\n",
        "    tokenizer = model_tokenizer_config[\"indic2en\"][\"tokenizer\"]\n",
        "    model = model_tokenizer_config[\"indic2en\"][\"model\"]\n",
        "\n",
        "    print(f\"Using indic2en, src_lang: {src_lang}, tgt_lang: {tgt_lang}\")\n",
        "\n",
        "\n",
        "  batch = ip.preprocess_batch(sents_to_translate, src_lang=src_lang, tgt_lang=tgt_lang, show_progress_bar=False)\n",
        "  batch = tokenizer(batch, padding=\"longest\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "\n",
        "  with inference_mode():\n",
        "      print(\"Generating...\")\n",
        "      outputs = model.generate(**batch, num_beams=5, num_return_sequences=1, max_length=256)\n",
        "\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "      outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "  if tgt_lang != \"en_Latn\":\n",
        "    print(f\"Postprocessing for {tgt_lang}\")\n",
        "    outputs = ip.postprocess_batch(outputs, lang=tgt_lang)\n",
        "\n",
        "\n",
        "  return outputs\n"
      ],
      "metadata": {
        "id": "4BZivpr8AJ4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indic translator test translation"
      ],
      "metadata": {
        "id": "doMPKMk45uta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sentences for translation\n",
        "test_sentences = [\"Hello, how are you?\", \"This is a test sentence.\"]\n",
        "\n",
        "# Call the indic_translate function\n",
        "translated = indic_translate(src_lang=\"english\", tgt_lang=\"hindi\", sents_to_translate=test_sentences)\n",
        "\n",
        "# Print the result\n",
        "print(\"Translated sentences:\", translated)\n"
      ],
      "metadata": {
        "id": "fte3Ia6f3NNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_ai4b_tts_model(lang: str):\n",
        "\n",
        "  \"\"\"\n",
        "  Download AI4Bharat's TTS models for a given language\n",
        "\n",
        "  Args:\n",
        "      lang (str): The language for which we want to download the model.\n",
        "  \"\"\"\n",
        "\n",
        "  lang_map = {\n",
        "      \"odia\": \"or\",\n",
        "      \"hindi\": \"hi\",\n",
        "      \"tamil\": \"ta\",\n",
        "      \"telugu\": \"te\",\n",
        "      \"punjabi\": \"pa\",\n",
        "      \"kannada\": \"kn\",\n",
        "      \"bengali\": \"bn\",\n",
        "      \"marathi\": \"mr\",\n",
        "      \"gujarati\": \"gu\",\n",
        "      \"malayalam\": \"ml\",\n",
        "  }\n",
        "\n",
        "  selected_lang = lang_map[lang]\n",
        "\n",
        "  download_path = f\"/content/{selected_lang}.zip\"\n",
        "\n",
        "  if os.path.exists(download_path):\n",
        "    print(f\"IndicTTS Model for {lang} already exists.\")\n",
        "\n",
        "  else:\n",
        "    !wget https://github.com/AI4Bharat/Indic-TTS/releases/download/v1-checkpoints-release/{selected_lang}.zip\n",
        "    !mkdir -p /content/models/v1\n",
        "    !unzip /content/{selected_lang}.zip -d /content/models/v1\n"
      ],
      "metadata": {
        "id": "blZmudGtAQYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_tts(text, tts_lang):\n",
        "\n",
        "  \"\"\"\n",
        "  Convert text to audio using IndicTTS\n",
        "\n",
        "  Args:\n",
        "      text (str): The input text, to be converted to audio.\n",
        "      tts_lang (str): The language in which the text is to be converted to audio.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  lang_map = {\n",
        "      \"odia\": \"or\",\n",
        "      \"hindi\": \"hi\",\n",
        "      \"tamil\": \"ta\",\n",
        "      \"telugu\": \"te\",\n",
        "      \"punjabi\": \"pa\",\n",
        "      \"kannada\": \"kn\",\n",
        "      \"bengali\": \"bn\",\n",
        "      \"marathi\": \"mr\",\n",
        "      \"gujarati\": \"gu\",\n",
        "      \"malayalam\": \"ml\",\n",
        "  }\n",
        "\n",
        "  download_ai4b_tts_model(lang=tts_lang)\n",
        "\n",
        "  tts_lang = lang_map[tts_lang]\n",
        "  print(f\"Lang code: {tts_lang}\")\n",
        "\n",
        "\n",
        "  tts_command = f'python3 -m TTS.bin.synthesize --text \"{text}\" \\\n",
        "    --model_path /content/models/v1/{tts_lang}/fastpitch/best_model.pth \\\n",
        "    --config_path /content/models/v1/{tts_lang}/fastpitch/config.json \\\n",
        "    --vocoder_path /content/models/v1/{tts_lang}/hifigan/best_model.pth \\\n",
        "    --vocoder_config_path /content/models/v1/{tts_lang}/hifigan/config.json \\\n",
        "    --speakers_file_path /content/models/v1/{tts_lang}/fastpitch/speakers.pth \\\n",
        "    --out_path /content/tts_output.wav \\\n",
        "    --speaker_idx male'\n",
        "\n",
        "  if DEVICE == \"cuda\":\n",
        "    tts_command += \" --use_cuda True\"\n",
        "    print(f\"Running IndicTTS on GPU\")\n",
        "\n",
        "  else:\n",
        "    print(f\"Running IndicTTS on CPU\")\n",
        "\n",
        "  os.system(tts_command)"
      ],
      "metadata": {
        "id": "UeFmnshpAV3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indic translator and TTS model test runing\n"
      ],
      "metadata": {
        "id": "6nja_zr25iGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Translate the text\n",
        "test_sentences = [\"Hello, how are you?\", \"This is a test sentence.\"]\n",
        "translated_sentences = indic_translate(src_lang=\"english\", tgt_lang=\"hindi\", sents_to_translate=test_sentences)\n",
        "\n",
        "# Step 2: Generate speech for each translated sentence using the TTS model\n",
        "for sentence in translated_sentences:\n",
        "    # Call the TTS function defined in your notebook\n",
        "    tts_audio_output = download_ai4b_tts_model(lang=\"hindi\")  # Replace with the actual TTS function call if needed\n",
        "\n",
        "    # Print or play the audio output\n",
        "    print(f\"Generated TTS audio for the translated sentence: {sentence}\")\n",
        "    # Example: Play the audio, save it as a file, or display the audio waveform\n",
        "    # play_audio(tts_audio_output)  # Replace with actual audio playback code\n"
      ],
      "metadata": {
        "id": "rFHXbBqJ37X8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/asr_models\n",
        "\n",
        "def download_ai4b_asr_model(lang: str):\n",
        "  \"\"\"\n",
        "  Download AI4Bharat's ASR models for a given language\n",
        "\n",
        "  Args:\n",
        "      lang (str): The language for which we want to download the model.\n",
        "  \"\"\"\n",
        "\n",
        "  available_langs = {\n",
        "      \"odia\": \"or\",\n",
        "      \"hindi\": \"hi\",\n",
        "      \"tamil\": \"ta\",\n",
        "      \"telugu\": \"te\",\n",
        "      \"punjabi\": \"pa\",\n",
        "      \"kannada\": \"kn\",\n",
        "      \"bengali\": \"bn\",\n",
        "      \"marathi\": \"mr\",\n",
        "      \"gujarati\": \"gu\",\n",
        "      \"malayalam\": \"ml\",\n",
        "  }\n",
        "\n",
        "  download_path = f\"/content/asr_models/ai4b_indicConformer_{available_langs[lang]}.nemo\"\n",
        "  print(f\"Downloaded ASR model path: {download_path}\")\n",
        "\n",
        "  if os.path.exists(download_path):\n",
        "      print(f\"Model for {lang} already exists.\")\n",
        "\n",
        "  elif lang not in available_langs:\n",
        "      raise ValueError(f\"Invalid language code: {lang}\")\n",
        "\n",
        "  else:\n",
        "    !wget https://objectstore.e2enetworks.net/indic-asr-public/indicConformer/ai4b_indicConformer_{available_langs[lang]}.nemo -O '/content/asr_models/ai4b_indicConformer_{available_langs[lang]}.nemo'\n",
        "\n",
        "  return download_path"
      ],
      "metadata": {
        "id": "F5Oxd4F8AdIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe(audio: str, lang: str):\n",
        "\n",
        "    \"\"\"\n",
        "    Uses IndicASR to transcribe the input audio to text, utilizing a Conformer NeMo model trained of Shrutilipi and IndicSuperb by AI4Bharat\n",
        "\n",
        "    Args:\n",
        "        audio (str): The input audio's path.\n",
        "        lang (str): The language of the input audio.\n",
        "\n",
        "    Returns:\n",
        "        transcription: The transcription of input audio.\n",
        "    \"\"\"\n",
        "\n",
        "    lang_map = {\n",
        "      \"odia\": \"or\",\n",
        "      \"hindi\": \"hi\",\n",
        "      \"tamil\": \"ta\",\n",
        "      \"telugu\": \"te\",\n",
        "      \"punjabi\": \"pa\",\n",
        "      \"kannada\": \"kn\",\n",
        "      \"bengali\": \"bn\",\n",
        "      \"marathi\": \"mr\",\n",
        "      \"gujarati\": \"gu\",\n",
        "      \"malayalam\": \"ml\",\n",
        "    }\n",
        "\n",
        "    download_path = download_ai4b_asr_model(lang=lang)\n",
        "\n",
        "    asr_model = nemo_asr.models.ASRModel.restore_from(\n",
        "          download_path, map_location=DEVICE\n",
        "    )\n",
        "\n",
        "    transcription = asr_model.transcribe(audio, batch_size=1, language_id=lang_map[lang])[0][0]\n",
        "    print(f\"Transcription: {transcription}\")\n",
        "\n",
        "    return transcription"
      ],
      "metadata": {
        "id": "Fez8L5wKAirk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_vector_db(query):\n",
        "\n",
        "  \"\"\"\n",
        "  Query the FAISS vector DB\n",
        "\n",
        "  Args:\n",
        "      query (str): The audio query.\n",
        "\n",
        "  Returns:\n",
        "      result (str): Combines top-3 Most similar documents corresponding to the user's query.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Combine the top-3 similar documents from the vectorDB\n",
        "  result = \" \".join([result.page_content for result in faiss.similarity_search(query, k=3)])\n",
        "\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "E2ftrugxAtqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "def process_user_query(user_query, retrieved_doc):\n",
        "\n",
        "  \"\"\"\n",
        "  Uses GPT-3.5-Turbo to extract the part of the retrieved document from vectorDB which is relevant to user's query\n",
        "\n",
        "  Args:\n",
        "      user_query (str): The user's question.\n",
        "      retrieved_doc (str): The information relevant to user's query.\n",
        "\n",
        "  Returns:\n",
        "      processed_doc: TThe extracted information from the given document.\n",
        "  \"\"\"\n",
        "\n",
        "  prompt_template = PromptTemplate.from_template(\n",
        "    \"You are a chatbot , which provides information to user based on their queries, \\\n",
        "    the user asks: {user_query}, The information from the related query is: {retrieved_doc}. \\\n",
        "    Now give the output based on the query and relevant information that i provided, written in a structured, well-formatted and concise way. \\\n",
        "    The length of the output should be no more than 70 words, must be in 5 lines.\"\n",
        "  )\n",
        "\n",
        "  prompt = prompt_template.format(user_query=user_query, retrieved_doc=retrieved_doc)\n",
        "\n",
        "  processed_doc = get_gemini_output(prompt)\n",
        "  print(processed_doc)\n",
        "\n",
        "  return processed_doc\n"
      ],
      "metadata": {
        "id": "uMwJ2w18AyKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_gradio_input(audio, user_lang):\n",
        "\n",
        "  \"\"\"\n",
        "  End-to-end voice assistant pipeline, no. of inputs and outputs are defined in the Gradio interface\n",
        "\n",
        "  Args:\n",
        "      audio (str): The audio path.\n",
        "      lang (str): The user's input language.\n",
        "\n",
        "  Returns:\n",
        "      en_to_indic_doc: The first return value. It is the final answer to user's query.\n",
        "      audio_outfile_path: The second return value. Path to the generated audio having the final answer.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Use IndicASR to transcribe the input audio\n",
        "  print(f\"Transcribing...\")\n",
        "  query_transcription = transcribe(audio, lang=user_lang)\n",
        "\n",
        "  # Convert the Indic text from transcription to English, so that GPT-3.5 can process it\n",
        "  print(f\"Translating indic to en..\")\n",
        "  indic_to_en = indic_translate(src_lang=user_lang, tgt_lang=\"english\", sents_to_translate=[query_transcription])[0]\n",
        "\n",
        "  # Query the Vector DB to get the relevant document from the query\n",
        "  print(f\"Querying vector db\")\n",
        "  retrieved_doc = query_vector_db(indic_to_en)\n",
        "\n",
        "  # Extract relevant information from the retrieved document\n",
        "  print(f\"Processing user query\")\n",
        "  processed_doc = process_user_query(user_query=indic_to_en, retrieved_doc=retrieved_doc)\n",
        "\n",
        "  # Break the document into chunks for faster batch processing\n",
        "  print(f\"Breaking document into chunks..\")\n",
        "  processed_doc_chunks = processed_doc.strip().split(\". \")\n",
        "  processed_doc_chunks = [f\"{chunk}.\" for chunk in processed_doc_chunks if chunk != \"\"]\n",
        "\n",
        "  # Translate the the extracted information back to Indic language\n",
        "  print(f\"Translating en to indic..\")\n",
        "  en_to_indic_chunks = indic_translate(src_lang=\"english\", tgt_lang=user_lang, sents_to_translate=processed_doc_chunks)\n",
        "  en_to_indic_doc = \" \".join(en_to_indic_chunks)\n",
        "  print(f\"en_to_indic_doc: {en_to_indic_doc}\")\n",
        "\n",
        "  # Run IndicTTS to generate audio\n",
        "  print(f\"Running TTS to generate audio..\")\n",
        "  run_tts(text=en_to_indic_doc, tts_lang=user_lang)\n",
        "  print(\"Finished running TTS\")\n",
        "\n",
        "  audio_outfile_path = \"/content/tts_output.wav\"\n",
        "\n",
        "\n",
        "  return en_to_indic_doc, audio_outfile_path\n"
      ],
      "metadata": {
        "id": "qTE895bmA461"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def launch_gradio_app(show_log=False):\n",
        "\n",
        "  \"\"\"\n",
        "  Launches the Gradio app for the voice assistant pipeline\n",
        "\n",
        "  Args:\n",
        "      show_log (bool): Whether to show the pipeline logs or not.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  languages = [\"hindi\", \"odia\", \"tamil\", \"telugu\", \"punjabi\", \"kannada\", \"bengali\", \"marathi\", \"gujarati\", \"malayalam\"]\n",
        "\n",
        "  iface = gr.Interface(\n",
        "      fn=process_gradio_input,\n",
        "      inputs=[\n",
        "          gr.Audio(sources=['upload', 'microphone'], type=\"filepath\", show_download_button=True),  # Input audio\n",
        "          gr.Dropdown(languages, label=\"Language\", value=\"hindi\"),  # Language selection\n",
        "      ],\n",
        "      outputs=[\"text\", \"audio\"],\n",
        "      allow_flagging=\"never\",\n",
        "      title=\"This is made by Srimadhav Varma\",\n",
        "      description=\"Know about latest farming schemes\",\n",
        "  )\n",
        "\n",
        "  iface.launch(debug=show_log)\n"
      ],
      "metadata": {
        "id": "NBDqT9cXBCls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "launch_gradio_app(show_log=False)\n"
      ],
      "metadata": {
        "id": "QO_RPVFqBLF8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}